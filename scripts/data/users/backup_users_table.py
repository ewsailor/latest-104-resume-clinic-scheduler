#!/usr/bin/env python3
"""
å‚™ä»½ users è³‡æ–™è¡¨è…³æœ¬

åœ¨ç§»é™¤ updated_by æ¬„ä½å‰ï¼Œå…ˆå‚™ä»½å®Œæ•´çš„ users è³‡æ–™è¡¨å…§å®¹ã€‚
"""

import json
import logging
import sys
from datetime import datetime
from pathlib import Path

# åŠ å…¥å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from sqlalchemy import create_engine, text  # noqa: E402

from app.core.settings import Settings  # noqa: E402

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def backup_users_table():
    """å‚™ä»½ users è³‡æ–™è¡¨"""

    # å»ºç«‹å‚™ä»½æª”æ¡ˆåç¨±ï¼ˆåŒ…å«æ™‚é–“æˆ³è¨˜ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_filename = f"users_backup_before_remove_updated_by_{timestamp}.json"
    backup_path = (
        project_root / "database" / "backups" / "data_backups" / backup_filename
    )

    logger.info(f"é–‹å§‹å‚™ä»½ users è³‡æ–™è¡¨...")
    logger.info(f"å‚™ä»½æª”æ¡ˆè·¯å¾‘: {backup_path}")

    # å»ºç«‹è³‡æ–™åº«é€£æ¥
    settings = Settings()
    engine = create_engine(settings.mysql_connection_string)

    try:
        with engine.connect() as conn:
            # è¨­å®šæ™‚å€
            conn.execute(text("SET time_zone = '+08:00'"))

            # æŸ¥è©¢æ‰€æœ‰ä½¿ç”¨è€…è³‡æ–™ï¼ˆåŒ…å«å·²åˆªé™¤çš„ï¼‰
            result = conn.execute(
                text(
                    """
                SELECT 
                    id,
                    name,
                    email,
                    created_at,
                    updated_at,
                    updated_by,
                    deleted_at
                FROM users
                ORDER BY id
            """
                )
            )

            users_data = []
            for row in result:
                user_dict = {
                    "id": row[0],
                    "name": row[1],
                    "email": row[2],
                    "created_at": row[3].isoformat() if row[3] else None,
                    "updated_at": row[4].isoformat() if row[4] else None,
                    "updated_by": row[5],
                    "deleted_at": row[6].isoformat() if row[6] else None,
                }
                users_data.append(user_dict)

            # å»ºç«‹å‚™ä»½è³‡æ–™çµæ§‹
            backup_data = {
                "backup_info": {
                    "timestamp": datetime.now().isoformat(),
                    "table_name": "users",
                    "total_records": len(users_data),
                    "description": "å‚™ä»½ users è³‡æ–™è¡¨ï¼Œæº–å‚™ç§»é™¤ updated_by æ¬„ä½",
                    "backup_type": "full_table_backup",
                },
                "table_schema": {
                    "columns": [
                        {"name": "id", "type": "INT UNSIGNED", "primary_key": True},
                        {"name": "name", "type": "VARCHAR(100)", "nullable": False},
                        {
                            "name": "email",
                            "type": "VARCHAR(191)",
                            "unique": True,
                            "nullable": False,
                        },
                        {"name": "created_at", "type": "DATETIME", "nullable": False},
                        {"name": "updated_at", "type": "DATETIME", "nullable": False},
                        {
                            "name": "updated_by",
                            "type": "INT UNSIGNED",
                            "nullable": True,
                            "foreign_key": "users.id",
                        },
                        {"name": "deleted_at", "type": "DATETIME", "nullable": True},
                    ]
                },
                "data": users_data,
            }

            # å¯«å…¥ JSON æª”æ¡ˆ
            with open(backup_path, 'w', encoding='utf-8') as f:
                json.dump(backup_data, f, ensure_ascii=False, indent=2)

            logger.info(f"âœ… æˆåŠŸå‚™ä»½ {len(users_data)} ç­†ä½¿ç”¨è€…è¨˜éŒ„")
            logger.info(f"å‚™ä»½æª”æ¡ˆ: {backup_path}")

            # é¡¯ç¤ºå‚™ä»½çµ±è¨ˆ
            active_users = len([u for u in users_data if u["deleted_at"] is None])
            deleted_users = len([u for u in users_data if u["deleted_at"] is not None])
            users_with_updated_by = len(
                [u for u in users_data if u["updated_by"] is not None]
            )

            logger.info(f"ğŸ“Š å‚™ä»½çµ±è¨ˆ:")
            logger.info(f"  - ç¸½è¨˜éŒ„æ•¸: {len(users_data)}")
            logger.info(f"  - æ´»èºä½¿ç”¨è€…: {active_users}")
            logger.info(f"  - å·²åˆªé™¤ä½¿ç”¨è€…: {deleted_users}")
            logger.info(f"  - æœ‰ updated_by çš„ä½¿ç”¨è€…: {users_with_updated_by}")

            # é¡¯ç¤ºå‰å¹¾ç­†è³‡æ–™ä½œç‚ºç¯„ä¾‹
            logger.info(f"ğŸ“‹ å‰ 5 ç­†è³‡æ–™ç¯„ä¾‹:")
            for i, user in enumerate(users_data[:5]):
                logger.info(
                    f"  {i+1}. ID {user['id']}: {user['name']} ({user['email']}) - updated_by: {user['updated_by']}"
                )

            return backup_path

    except Exception as e:
        logger.error(f"âŒ å‚™ä»½å¤±æ•—: {str(e)}")
        raise


def verify_backup(backup_path):
    """é©—è­‰å‚™ä»½æª”æ¡ˆ"""

    logger.info(f"é©—è­‰å‚™ä»½æª”æ¡ˆ: {backup_path}")

    try:
        with open(backup_path, 'r', encoding='utf-8') as f:
            backup_data = json.load(f)

        # é©—è­‰å‚™ä»½è³‡æ–™çµæ§‹
        required_keys = ["backup_info", "table_schema", "data"]
        for key in required_keys:
            if key not in backup_data:
                raise ValueError(f"å‚™ä»½æª”æ¡ˆç¼ºå°‘å¿…è¦æ¬„ä½: {key}")

        # é©—è­‰è³‡æ–™å®Œæ•´æ€§
        users_data = backup_data["data"]
        logger.info(f"âœ… å‚™ä»½æª”æ¡ˆé©—è­‰æˆåŠŸ")
        logger.info(f"  - è¨˜éŒ„æ•¸: {len(users_data)}")
        logger.info(f"  - å‚™ä»½æ™‚é–“: {backup_data['backup_info']['timestamp']}")

        return True

    except Exception as e:
        logger.error(f"âŒ å‚™ä»½æª”æ¡ˆé©—è­‰å¤±æ•—: {str(e)}")
        return False


def main():
    """ä¸»å‡½æ•¸"""

    logger.info("=== é–‹å§‹å‚™ä»½ users è³‡æ–™è¡¨ ===")

    try:
        # åŸ·è¡Œå‚™ä»½
        backup_path = backup_users_table()

        # é©—è­‰å‚™ä»½
        if verify_backup(backup_path):
            logger.info("ğŸ‰ å‚™ä»½å®Œæˆï¼å¯ä»¥å®‰å…¨åœ°é€²è¡Œè³‡æ–™è¡¨çµæ§‹ä¿®æ”¹")
        else:
            logger.error("âŒ å‚™ä»½é©—è­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥å‚™ä»½æª”æ¡ˆ")
            sys.exit(1)

    except Exception as e:
        logger.error(f"å‚™ä»½éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()
